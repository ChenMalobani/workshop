{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_1_binary.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LOrWdGJA8wg",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eyaler/workshop/blob/master/nn_1_binary.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lVenku6TeQn4"
      },
      "source": [
        "# 1. Neural networks and back propagation for binary classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ORCzVz_VeQn9",
        "colab": {}
      },
      "source": [
        "# import required packages\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons\n",
        "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yiv15UAKeQoK",
        "colab": {}
      },
      "source": [
        "# create data\n",
        "XX, YY = make_moons(n_samples=1000, noise=.2, random_state=41)\n",
        "with open('ex1.csv','w') as f:\n",
        "    f.writelines('%f,%f,%f\\n'%(x[0],x[1],y) for x,y in zip (XX,YY))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sutNxxRreQoS",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# load data\n",
        "data = np.genfromtxt('ex1.csv', delimiter=',')\n",
        "num_examples = len(data)\n",
        "print(num_examples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zvc83MjdeQof",
        "colab": {}
      },
      "source": [
        "# randomize data and split to train and test\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(data)\n",
        "\n",
        "split = int(num_examples*0.8)\n",
        "train = data[:split]\n",
        "test = data[split:]\n",
        "print(train.shape, test.shape)\n",
        "print(train[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EXsRLZFYeQon",
        "colab": {}
      },
      "source": [
        "# get features and labels\n",
        "X_train, y_train = train[:,:2], train[:,2]\n",
        "X_test, y_test = test[:,:2], test[:,2]\n",
        "\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(y_train.shape, y_test.shape)\n",
        "\n",
        "# visulize the training set\n",
        "plt.scatter(X_train[:,0], X_train[:,1], s=40, c=y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3hoG0LgJeQou",
        "colab": {}
      },
      "source": [
        "#setup weight martices and initialize\n",
        "def init_weights(num_input_nodes, num_output_nodes):\n",
        "    return np.random.uniform(low=-1, high=1, size=(num_input_nodes, num_output_nodes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9WnCMSdneQo1",
        "colab": {}
      },
      "source": [
        "#implement sigmoid function\n",
        "def sigmoid(z):\n",
        "    #your code here:\n",
        "    ret = 1/(1+np.exp(-z))\n",
        "    \n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L1r6PnhVeQo9",
        "colab": {}
      },
      "source": [
        "#implement cross entropy\n",
        "def cross_entropy(H, y):\n",
        "    #your code here:\n",
        "    ret = -np.log(H+1e-10)*y-np.log(1-H+1e-10)*(1-y)\n",
        "    \n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "18eTbVUUeQpH",
        "colab": {}
      },
      "source": [
        "def is_correct(H, y):\n",
        "    #your code here:\n",
        "    ret = (H>=0.5) == y\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4kfjYKQ-eQpU",
        "colab": {}
      },
      "source": [
        "#implement layer - compute values at output of layer (after sigmoid activation)\n",
        "def compute_layer(inputs_to_layer, weights):\n",
        "    #your code here:\n",
        "    ret = sigmoid(weights.T@inputs_to_layer)\n",
        "    \n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o2_7dkQLeQpb",
        "colab": {}
      },
      "source": [
        "def forward_pass(x, w, m):\n",
        "    x = np.expand_dims(x, axis=-1)\n",
        "    h = compute_layer(x, w)\n",
        "    h = np.vstack((np.ones((1,1)), h)) # added a constant hidden node for bias calculations\n",
        "    H = compute_layer(h, m)[0,0]\n",
        "    return x,h,H"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3SysEXXGeQpi",
        "colab": {}
      },
      "source": [
        "def backward_pass(x, h, H, y, m):\n",
        "    #your code here:\n",
        "    djdm = (H-y)*h\n",
        "    djdw = (djdm*m*(1-h))[1:].T*x # 1: to ignore bias term\n",
        "    return djdm, djdw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XhkHlH5neQpp",
        "colab": {}
      },
      "source": [
        "def train(features, labels, num_epochs, num_hidden_nodes, learning_rate):\n",
        "    features = np.hstack((np.ones((len(features),1)), features)) # added a constant input node for bias calculations\n",
        "    num_examples, num_features = features.shape\n",
        "    w = init_weights(num_features, num_hidden_nodes)\n",
        "    m = init_weights(num_hidden_nodes+1, 1) # +1 to allow bias calculations\n",
        "    for i in range(num_epochs):\n",
        "        loss = 0\n",
        "        count_correct = 0\n",
        "        sum_djdm = 0\n",
        "        sum_djdw = 0\n",
        "        for x, y in zip(features, labels):\n",
        "            x, h, H = forward_pass(x, w, m)\n",
        "            loss += cross_entropy(H, y)\n",
        "            count_correct += is_correct(H, y)\n",
        "            djdm, djdw = backward_pass(x, h, H, y, m)\n",
        "            sum_djdm += djdm\n",
        "            sum_djdw += djdw\n",
        "        m -= learning_rate*sum_djdm/num_examples\n",
        "        w -= learning_rate*sum_djdw/num_examples\n",
        "        if (i+1)%100==0:\n",
        "            print(i+1, loss/num_examples, count_correct/num_examples)\n",
        "    return w, m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3FUc4nF3eQpt",
        "colab": {}
      },
      "source": [
        "def test(features, labels, w, m):\n",
        "    features = np.hstack((np.ones((len(features),1)), features)) # added a constant input node for bias calculations\n",
        "    num_examples, num_features = features.shape\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    for x, y in zip(features, labels):\n",
        "        x, h, H = forward_pass(x, w, m)\n",
        "        loss += cross_entropy(H, y)\n",
        "        acc += correct(H, y)\n",
        "    return loss/num_examples, acc/num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0A12hCf6eQpy",
        "colab": {}
      },
      "source": [
        "def predict(features, w, m):\n",
        "    features = np.hstack((np.ones((len(features),1)), features)) # added a constant input node for bias calculations\n",
        "    pred = []\n",
        "    for x in features:\n",
        "        x, h, H = forward_pass(x, w, m)\n",
        "        pred.append(1 if H>=0.5 else 0)\n",
        "    return np.array(pred)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vAZLmh4A8zC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_probs(features, w, m):\n",
        "    features = np.hstack((np.ones((len(features),1)), features)) # added a constant input node for bias calculations\n",
        "    prob = []\n",
        "    for x in features:\n",
        "        x, h, H = forward_pass(x, w, m)\n",
        "        prob.append(H)\n",
        "    return np.array(prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NFWwCfUZeQp4",
        "colab": {}
      },
      "source": [
        "# Decision boundary visualization\n",
        "\n",
        "def plot_decision_boundary(features, labels, w, m):\n",
        "    # Set min and max values and give it some padding\n",
        "    x_min, x_max = features[:, 0].min() - .5, features[:, 0].max() + .5\n",
        "    y_min, y_max = features[:, 1].min() - .5, features[:, 1].max() + .5\n",
        "    \n",
        "    # Generate a grid of points with distance h between them\n",
        "    h = 0.01\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), \n",
        "                         np.arange(y_min, y_max, h))\n",
        "    \n",
        "    # Predict the function value for the whole grid\n",
        "    g = predict(np.c_[xx.ravel(), yy.ravel()], w, m)\n",
        "    g = g.reshape(xx.shape)\n",
        "    \n",
        "    # Plot the contour and test examples\n",
        "    plt.contourf(xx, yy, g, cmap=plt.cm.Spectral)\n",
        "    plt.scatter(features[:, 0], features[:, 1], s=40, c=labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nZFwL1aTeQp8",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# what do you think about the following results?\n",
        "w,m = train(X_train, y_train, num_epochs=300, num_hidden_nodes=2, learning_rate=0.1)\n",
        "loss,acc = test(X_test, y_test, w, m)\n",
        "print ('\\ntest:',loss,acc)\n",
        "plot_decision_boundary(X_test, y_test, w, m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bFb-xZxPeQqQ",
        "colab": {}
      },
      "source": [
        "# find a setting of epochs, hidden units and learning rates with better results. how do these parameters affect the results?\n",
        "w,m = train(X_train, y_train, num_epochs=1000, num_hidden_nodes=10, learning_rate=10)\n",
        "loss,acc = test(X_test, y_test, w, m)\n",
        "print ('\\ntest:',loss,acc)\n",
        "plot_decision_boundary(X_test, y_test, w, m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "N4LSGCxBA8zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ROC and AUC\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = get_probs(X_test, w, m)\n",
        "fpr, tpr, threshold = roc_curve(y_test, probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.3f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([-0.1, 1.1])\n",
        "plt.ylim([-0.1, 1.1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}