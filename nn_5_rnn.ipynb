{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eyaler/workshop/blob/master/nn_5_rnn.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "csvOItTNfHqk"
   },
   "source": [
    "# 5. Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mudsfWpldVGN"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "from python.keras import Input, Model\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import get_file\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fifPjuOxdVGe"
   },
   "outputs": [],
   "source": [
    "# set random seeds for more reproducible results\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHczAfijdVGm",
    "outputId": "2c0ab331-310f-4ed2-d216-c7c856c7ecc3"
   },
   "outputs": [],
   "source": [
    "path = get_file('trump.txt', origin='https://raw.githubusercontent.com/ryanmcdermott/trump-speeches/master/speeches.txt')\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print(Counter(text))\n",
    "text = unidecode(text).lower()\n",
    "text = re.sub('\\n+','\\n',text)\n",
    "text = re.sub(r'[^a-z0-9 \\n.,\\'\"?!$%-]','',text)\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QvFaN3mqdVG2",
    "outputId": "051defc5-56cd-40da-9a64-699b7b8eb16a"
   },
   "outputs": [],
   "source": [
    "chars = sorted(set(text))\n",
    "print('vocab size:', len(chars))\n",
    "char_indices = {c:i for i, c in enumerate(chars)}\n",
    "indices_char = {i:c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIG9breGdVG_"
   },
   "outputs": [],
   "source": [
    "# cut the text in semi-redundant sequences of max_seq_len characters\n",
    "max_seq_len = 40\n",
    "step = 3\n",
    "\n",
    "def get_seq(data):\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(data) - max_seq_len, step):\n",
    "        sentences.append(data[i: i + max_seq_len])\n",
    "        next_chars.append(data[i + max_seq_len])\n",
    "    \n",
    "    # vectorize:\n",
    "    x = np.zeros((len(sentences), max_seq_len, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gU9ugd6zdVHI",
    "outputId": "67ddd233-ff0c-4d76-f66b-a461dfd267eb"
   },
   "outputs": [],
   "source": [
    "split_idx = int(len(text)*0.9)\n",
    "train = text[:split_idx]\n",
    "valid = text[split_idx:]\n",
    "\n",
    "x,y = get_seq(train)\n",
    "print('number of sequences in train:', len(x))\n",
    "x_val,y_val = get_seq(valid)\n",
    "print('number of sequences in validation:', len(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N0sbzN1OdVHR"
   },
   "outputs": [],
   "source": [
    "# build the model\n",
    "def get_model(max_seq_len, vocab_size, nodes, depth=1):\n",
    "    inputs = Input(shape=(max_seq_len, len(chars)))\n",
    "    f = inputs\n",
    "    for i in range(depth):\n",
    "        f = LSTM(nodes, dropout=0.2, recurrent_dropout=0.2, return_sequences=i<depth-1)(f)\n",
    "    f = Dropout(0.2)(f)\n",
    "    outputs = Dense(len(chars), activation='softmax')(f)\n",
    "    return Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8obg9J_dVHX"
   },
   "outputs": [],
   "source": [
    "#temperature = 0\n",
    "#temperature = 1\n",
    "temperature = 0.5\n",
    "\n",
    "def get_next_char(preds):\n",
    "     # these are necessary due to numerical precision issues:\n",
    "    preds = np.asarray(preds, dtype=np.float64)\n",
    "    preds = preds / np.sum(preds)\n",
    "    \n",
    "    # your code here:\n",
    "    if temperature == 0:\n",
    "        probas = preds\n",
    "    elif temperature == 1:\n",
    "        probas = np.random.multinomial(1, preds)\n",
    "    else:\n",
    "        # helper function to sample an index from a probability array\n",
    "        exp_preds = np.exp(np.log(preds+1e-6) / temperature)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds)\n",
    "    next_index = np.argmax(probas)\n",
    "    return indices_char[next_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2vc_yzILdVHf"
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    if epoch%10 != 0:\n",
    "        return\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    data = valid\n",
    "    \n",
    "    start_index = np.random.randint(0, len(data) - max_seq_len - 1)\n",
    "        \n",
    "    sentence = data[start_index: start_index + max_seq_len]\n",
    "    generated = sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    print()\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, max_seq_len, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_char = get_next_char(preds)\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JmlEVFlLdVHp"
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "batch_size = 128\n",
    "epochs = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q_njrwyGdVHy",
    "outputId": "c80cbd8f-f721-4ba2-f1c6-5bc805f81836"
   },
   "outputs": [],
   "source": [
    "model = get_model(max_seq_len, len(chars), 128, depth=1)\n",
    "print(model.summary())\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "seed(42)\n",
    "set_random_seed(43)\n",
    "\n",
    "history = model.fit(x, y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[print_callback], validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-VlbLcqdVH7",
    "outputId": "ab7faad6-b5b4-45d4-d45b-49000366c3ba"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Ms-KO1DdVIE",
    "outputId": "7af50144-01c6-494e-f151-e4cf32449d96"
   },
   "outputs": [],
   "source": [
    "model = get_model(max_seq_len, len(chars), 64, depth=2)\n",
    "print(model.summary())\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "seed(42)\n",
    "set_random_seed(43)\n",
    "\n",
    "history = model.fit(x, y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[print_callback], validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_GzI5sifdVIK",
    "outputId": "a71900c0-0cba-4682-b519-064f3f34bd4d"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nn_5_rnn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
