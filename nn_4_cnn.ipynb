{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_4_cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjNfQQezBBtl",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eyaler/workshop/blob/master/nn_4_cnn.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VPL9z9UsfEgd"
      },
      "source": [
        "# 4. Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jaJB3RfDdoPl",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from keras import Input, Model\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.datasets import mnist, cifar10\n",
        "from keras.utils import to_categorical\n",
        "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wq3kt-CcdoPu",
        "colab": {}
      },
      "source": [
        "# set random seeds for more reproducible results\n",
        "from numpy.random import seed\n",
        "seed(42)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(43)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OFIQLJfAdoP4",
        "colab": {}
      },
      "source": [
        "# load dataset\n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "gray = False\n",
        "if len(x_train.shape)==4 and gray:\n",
        "    x_train = np.mean(x_train, axis=-1, keepdims=True)\n",
        "    x_test = np.mean(x_test, axis=-1, keepdims=True)\n",
        "if len(x_train.shape)==3:\n",
        "    x_train = np.expand_dims(x_train, axis=-1)\n",
        "    x_test = np.expand_dims(x_test, axis=-1)\n",
        "train_size = len(y_train)\n",
        "test_size = len(y_test)\n",
        "xdim = x_train.shape[1]\n",
        "ydim = x_train.shape[2]\n",
        "cdim = x_train.shape[3]\n",
        "print(x_train.dtype, y_train.dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xOR0rcAvdoQD",
        "colab": {}
      },
      "source": [
        "print(x_train[0])\n",
        "print(y_train[0])\n",
        "if gray:\n",
        "    plt.imshow(x_train[0][..., 0], cmap='gray')\n",
        "else:\n",
        "    plt.imshow(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aByrOryzdoQL",
        "colab": {}
      },
      "source": [
        "print(np.min(x_train), np.max(x_train), np.median(x_train))\n",
        "print(np.unique(y_train, return_counts=True))\n",
        "print(np.unique(y_test, return_counts=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3OSVDe_sdoQR",
        "colab": {}
      },
      "source": [
        "n_classes = len(np.unique(y_test))\n",
        "x_train, y_train = shuffle(x_train, y_train, random_state=44)\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255\n",
        "y_train = to_categorical(y_train, n_classes)\n",
        "y_test = to_categorical(y_test, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mgy7JjGgdoQd",
        "colab": {}
      },
      "source": [
        "def get_model(bn):\n",
        "    inputs = Input(shape=(xdim, ydim, cdim))\n",
        "    f = Conv2D(filters=32, kernel_size=3, activation='relu')(inputs)\n",
        "    if bn:\n",
        "        f = BatchNormalization()(f)\n",
        "    f = Conv2D(filters=32, kernel_size=3, activation='relu')(f)\n",
        "    if bn:\n",
        "        f = BatchNormalization()(f)\n",
        "    f = MaxPooling2D()(f)\n",
        "    f = Dropout(0.25)(f)\n",
        "    f = Conv2D(filters=64, kernel_size=3, activation='relu')(f)\n",
        "    if bn:\n",
        "        f = BatchNormalization()(f)\n",
        "    f = Conv2D(filters=64, kernel_size=3, activation='relu')(f)\n",
        "    if bn:\n",
        "        f = BatchNormalization()(f)\n",
        "    f = MaxPooling2D()(f)\n",
        "    f = Dropout(0.25)(f)\n",
        "    f = Flatten()(f)\n",
        "    f = Dense(512, activation='relu')(f)\n",
        "    f = Dropout(0.5)(f)\n",
        "    outputs = Dense(n_classes, activation='softmax')(f)\n",
        "    return Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3JaZWamydoQk",
        "colab": {}
      },
      "source": [
        "model = get_model(bn=False)\n",
        "print(model.summary())\n",
        "print((3*3*3+1)*32+(3*3*32+1)*32+(3*3*32+1)*64+(3*3*64+1)*64+((((32-2-2)/2-2-2)/2)**2*64+1)*512+(512+1)*10)\n",
        "print('https://fomoro.com/tools/receptive-fields/#3,1,1,VALID;3,1,1,VALID;2,2,1,VALID;3,1,1,VALID;3,1,1,VALID;2,2,1,VALID')\n",
        "print(3+2+1+2*(2+2+1))\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(x=x_train, y=y_train, batch_size=64, epochs=150, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eMJmS5NWdoQw",
        "colab": {}
      },
      "source": [
        "model = get_model(bn=True)\n",
        "print(model.summary())\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(x=x_train, y=y_train, batch_size=64, epochs=150, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JTpa8BPedoQ5",
        "colab": {}
      },
      "source": [
        "model = get_model(bn=True)\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True, width_shift_range=0.1, height_shift_range=0.1)\n",
        "\n",
        "valid_idx = int(train_size*0.8)\n",
        "aug_train_data = datagen.flow(x=x_train[:valid_idx], y=y_train[:valid_idx], batch_size=64, seed=45)\n",
        "valid_data = (x_train[valid_idx:], y_train[valid_idx:])\n",
        "history = model.fit_generator(aug_train_data, epochs=150, steps_per_epoch=valid_idx // 64, validation_data=valid_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tzwkn83-doRA",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UHNWmqPZdoRH",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "loss, acc = model.evaluate(x=x_test, y=y_test)\n",
        "print(loss, acc)\n",
        "targets = np.argmax(y_test, axis=-1)\n",
        "probabilities = model.predict(x=x_test)\n",
        "predictions = np.argmax(probabilities, axis=-1)\n",
        "cm = confusion_matrix(y_true=targets, y_pred=predictions)\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wpczivZJdoRN",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        title = 'Normalized confusion matrix'\n",
        "    else:\n",
        "        title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    np.set_printoptions(precision=2)\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "classes = np.arange(n_classes)\n",
        "plot_confusion_matrix(cm, classes=classes)\n",
        "plot_confusion_matrix(cm, classes=classes, normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-BGouqTQdoRT",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "report = classification_report(y_true=targets, y_pred=predictions, labels=classes, target_names=class_names)\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cYlQPvOWdoRd",
        "colab": {}
      },
      "source": [
        "# top errors\n",
        "from sklearn.metrics import log_loss\n",
        "max_probs = np.max(probabilities, axis=-1)\n",
        "losses = [log_loss(y_true=y, y_pred=prob, eps=1e-7) for y,prob in zip(y_test,probabilities)]\n",
        "print('loss\\tindex\\ttrue\\t\\tpredicted\\tprobability')\n",
        "top_errors = sorted(list(zip(losses, np.arange(test_size), [class_names[t] for t in targets], [class_names[p] for p in predictions], max_probs)), reverse=True)[:10]\n",
        "for error in top_errors:\n",
        "    print('%.04f\\t%d\\t%s\\t\\t%s\\t\\t%.04f'%error)\n",
        "    plt.figure()\n",
        "    if gray:\n",
        "        plt.imshow(x_test[error[1]][..., 0], cmap='gray')\n",
        "    else:\n",
        "        plt.imshow(x_test[error[1]])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}