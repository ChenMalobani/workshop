{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eyaler/workshop/blob/master/nn_1_binary.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVenku6TeQn4"
   },
   "source": [
    "# 1. Neural networks and back propagation for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ORCzVz_VeQn9"
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiv15UAKeQoK"
   },
   "outputs": [],
   "source": [
    "# create data\n",
    "XX, YY = make_moons(n_samples=1000, noise=.2, random_state=41)\n",
    "with open('ex1.csv','w') as f:\n",
    "    f.writelines('%f,%f,%f\\n'%(x[0],x[1],y) for x,y in zip (XX,YY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1555157094490,
     "user": {
      "displayName": "Eyal Gruss",
      "photoUrl": "https://lh4.googleusercontent.com/-u09YaZrQAqY/AAAAAAAAAAI/AAAAAAAAC64/Edn8Phw0CRs/s64/photo.jpg",
      "userId": "10806915125759667398"
     },
     "user_tz": -180
    },
    "id": "sutNxxRreQoS",
    "outputId": "a88f947b-8f8e-4669-99a0-3aae87384fe2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = np.genfromtxt('ex1.csv', delimiter=',')\n",
    "num_examples = len(data)\n",
    "print(num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 694,
     "status": "ok",
     "timestamp": 1555157106962,
     "user": {
      "displayName": "Eyal Gruss",
      "photoUrl": "https://lh4.googleusercontent.com/-u09YaZrQAqY/AAAAAAAAAAI/AAAAAAAAC64/Edn8Phw0CRs/s64/photo.jpg",
      "userId": "10806915125759667398"
     },
     "user_tz": -180
    },
    "id": "zvc83MjdeQof",
    "outputId": "7a968728-5ddb-4b0d-d40f-8bd38b70453f"
   },
   "outputs": [],
   "source": [
    "# randomize data and split to train and test\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "split = int(num_examples*0.8)\n",
    "train = data[:split]\n",
    "test = data[split:]\n",
    "print(train.shape, test.shape)\n",
    "print(train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1410,
     "status": "ok",
     "timestamp": 1555157117864,
     "user": {
      "displayName": "Eyal Gruss",
      "photoUrl": "https://lh4.googleusercontent.com/-u09YaZrQAqY/AAAAAAAAAAI/AAAAAAAAC64/Edn8Phw0CRs/s64/photo.jpg",
      "userId": "10806915125759667398"
     },
     "user_tz": -180
    },
    "id": "EXsRLZFYeQon",
    "outputId": "2fac2a09-2850-4a42-8117-f74194d338c7"
   },
   "outputs": [],
   "source": [
    "# get features and labels\n",
    "X_train, y_train = train[:,:2], train[:,2]\n",
    "X_test, y_test = test[:,:2], test[:,2]\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "# visulize the training set\n",
    "plt.scatter(X_train[:,0], X_train[:,1], s=40, c=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hoG0LgJeQou"
   },
   "outputs": [],
   "source": [
    "#setup weight martices and initialize\n",
    "def init_weights(num_input_nodes, num_output_nodes):\n",
    "    return np.random.uniform(low=-1, high=1, size=(num_input_nodes, num_output_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9WnCMSdneQo1"
   },
   "outputs": [],
   "source": [
    "#implement sigmoid function\n",
    "def sigmoid(z):\n",
    "    #your code here:\n",
    "    ret = 1/(1+np.exp(-z))\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1r6PnhVeQo9"
   },
   "outputs": [],
   "source": [
    "#implement cross entropy\n",
    "def cross_entropy(H, y):\n",
    "    #your code here:\n",
    "    ret = -np.log(H+1e-10)*y-np.log(1-H+1e-10)*(1-y)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "18eTbVUUeQpH"
   },
   "outputs": [],
   "source": [
    "def accuracy(H, y):\n",
    "    #your code here:\n",
    "    ret = (H>=0.5)*y+(H<0.5)*(1-y)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4kfjYKQ-eQpU"
   },
   "outputs": [],
   "source": [
    "#implement layer - compute values at output of layer (after sigmoid activation)\n",
    "def compute_layer(inputs_to_layer, weights):\n",
    "    #your code here:\n",
    "    ret = sigmoid(weights.T@inputs_to_layer)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2_7dkQLeQpb"
   },
   "outputs": [],
   "source": [
    "def forward_pass(x, w, m):\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    h = compute_layer(x, w)\n",
    "    h = np.vstack((np.ones((1,1)), h)) # added a constant hidden node for bias calculations\n",
    "    H = compute_layer(h, m)[0,0]\n",
    "    return x,h,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3SysEXXGeQpi"
   },
   "outputs": [],
   "source": [
    "def backward_pass(x, h, H, y, m):\n",
    "    #your code here:\n",
    "    djdm = (H-y)*h\n",
    "    djdw = (djdm*m*(1-h))[1:].T*x # 1: to ignore bias term\n",
    "    return djdm, djdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XhkHlH5neQpp"
   },
   "outputs": [],
   "source": [
    "def train(features, labels, num_epochs, num_hidden, learning_rate):\n",
    "    features = np.hstack((np.ones((len(features),1)), features)) # added a constant input node for bias calculations\n",
    "    num_examples, num_features = features.shape\n",
    "    w = init_weights(num_features, num_hidden)\n",
    "    m = init_weights(num_hidden+1, 1) # +1 to allow bias calculations\n",
    "    for i in range(num_epochs):\n",
    "        loss = 0\n",
    "        acc = 0\n",
    "        sum_djdm = 0\n",
    "        sum_djdw = 0\n",
    "        for x, y in zip(features, labels):\n",
    "            x, h, H = forward_pass(x, w, m)\n",
    "            loss += cross_entropy(H, y)\n",
    "            acc += accuracy(H, y)\n",
    "            djdm, djdw = backward_pass(x, h, H, y, m)\n",
    "            sum_djdm += djdm\n",
    "            sum_djdw += djdw\n",
    "        m -= learning_rate*sum_djdm/num_examples\n",
    "        w -= learning_rate*sum_djdw/num_examples\n",
    "        if (i+1)%100==0:\n",
    "            print(i+1, loss/num_examples, acc/num_examples)\n",
    "    return w, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3FUc4nF3eQpt"
   },
   "outputs": [],
   "source": [
    "def test(features, labels, w, m):\n",
    "    features = np.hstack((np.ones((len(features),1)), features)) # added a constant input node for bias calculations\n",
    "    num_examples, num_features = features.shape\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    for x, y in zip(features, labels):\n",
    "        x, h, H = forward_pass(x, w, m)\n",
    "        loss += cross_entropy(H, y)\n",
    "        acc += accuracy(H, y)\n",
    "    return loss/num_examples, acc/num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0A12hCf6eQpy"
   },
   "outputs": [],
   "source": [
    "def predict(features, w, m):\n",
    "    features = np.hstack((np.ones((len(features),1)), features)) # added a constant input node for bias calculations\n",
    "    pred = []\n",
    "    for x in features:\n",
    "        x, h, H = forward_pass(x, w, m)\n",
    "        pred.append(1 if H>=0.5 else 0)\n",
    "    return np.array(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(features, w, m):\n",
    "    features = np.hstack((np.ones((len(features),1)), features)) # added a constant input node for bias calculations\n",
    "    prob = []\n",
    "    for x in features:\n",
    "        x, h, H = forward_pass(x, w, m)\n",
    "        prob.append(H)\n",
    "    return np.array(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFWwCfUZeQp4"
   },
   "outputs": [],
   "source": [
    "# Decision boundary visualization\n",
    "\n",
    "def plot_decision_boundary(features, labels, w, m):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = features[:, 0].min() - .5, features[:, 0].max() + .5\n",
    "    y_min, y_max = features[:, 1].min() - .5, features[:, 1].max() + .5\n",
    "    \n",
    "    # Generate a grid of points with distance h between them\n",
    "    h = 0.01\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), \n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Predict the function value for the whole grid\n",
    "    g = predict(np.c_[xx.ravel(), yy.ravel()], w, m)\n",
    "    g = g.reshape(xx.shape)\n",
    "    \n",
    "    # Plot the contour and test examples\n",
    "    plt.contourf(xx, yy, g, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(features[:, 0], features[:, 1], s=40, c=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17803,
     "status": "ok",
     "timestamp": 1555157185036,
     "user": {
      "displayName": "Eyal Gruss",
      "photoUrl": "https://lh4.googleusercontent.com/-u09YaZrQAqY/AAAAAAAAAAI/AAAAAAAAC64/Edn8Phw0CRs/s64/photo.jpg",
      "userId": "10806915125759667398"
     },
     "user_tz": -180
    },
    "id": "nZFwL1aTeQp8",
    "outputId": "3848c5ba-d896-4c55-bdfb-8c19b8187a4c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# what do you think about the following results?\n",
    "w,m = train(X_train, y_train, num_epochs=300, num_hidden=2, learning_rate=0.1)\n",
    "loss,acc = test(X_test, y_test, w, m)\n",
    "print ('\\ntest:',loss,acc)\n",
    "plot_decision_boundary(X_test, y_test, w, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46556,
     "status": "ok",
     "timestamp": 1555158097080,
     "user": {
      "displayName": "Eyal Gruss",
      "photoUrl": "https://lh4.googleusercontent.com/-u09YaZrQAqY/AAAAAAAAAAI/AAAAAAAAC64/Edn8Phw0CRs/s64/photo.jpg",
      "userId": "10806915125759667398"
     },
     "user_tz": -180
    },
    "id": "bFb-xZxPeQqQ",
    "outputId": "3b3a414d-89e6-4fc4-cd9c-3ae61ff89c3e"
   },
   "outputs": [],
   "source": [
    "# find a setting of epochs, hidden units and learning rates with better results. how do these parameters affect the results?\n",
    "w,m = train(X_train, y_train, num_epochs=1000, num_hidden=10, learning_rate=10)\n",
    "loss,acc = test(X_test, y_test, w, m)\n",
    "print ('\\ntest:',loss,acc)\n",
    "plot_decision_boundary(X_test, y_test, w, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ROC and AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = get_probs(X_test, w, m)\n",
    "fpr, tpr, threshold = roc_curve(y_test, probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.3f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "nn_1_binary.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
